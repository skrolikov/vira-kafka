package kafka

import (
	"context"
	"encoding/json"
	"time"

	"github.com/segmentio/kafka-go"
	log "github.com/skrolikov/vira-logger"
)

// MessageMiddleware –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏–∑–º–µ–Ω—è—Ç—å key/value –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π.
type MessageMiddleware func(ctx context.Context, key string, value []byte) (string, []byte, error)

// ProducerConfig –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–æ–∑–¥–∞–Ω–∏—è Kafka Producer.
type ProducerConfig struct {
	Brokers      []string
	Topic        string
	BatchTimeout time.Duration
	Async        bool

	RequiredAcks kafka.RequiredAcks
	Compression  kafka.Compression
	MaxAttempts  int

	Metrics     *KafkaMetrics
	Middlewares []MessageMiddleware
}

// Producer ‚Äî Kafka producer —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π middleware, –ª–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏.
type Producer struct {
	writer      *kafka.Writer
	logger      *log.Logger
	middlewares []MessageMiddleware
	metrics     *KafkaMetrics
	topic       string
}

// NewProducer —Å–æ–∑–¥–∞—ë—Ç –∏ –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç Kafka producer.
func NewProducer(cfg ProducerConfig, logger *log.Logger) *Producer {
	writer := &kafka.Writer{
		Addr:         kafka.TCP(cfg.Brokers...),
		Topic:        cfg.Topic,
		Balancer:     &kafka.LeastBytes{},
		RequiredAcks: cfg.RequiredAcks,
		Async:        cfg.Async,
		BatchTimeout: cfg.BatchTimeout,
		Compression:  cfg.Compression,
		MaxAttempts:  cfg.MaxAttempts,
	}

	logger.Info("‚úÖ Kafka producer —Å–æ–∑–¥–∞–Ω –¥–ª—è topic: %s", cfg.Topic)

	return &Producer{
		writer:      writer,
		logger:      logger,
		middlewares: cfg.Middlewares,
		metrics:     cfg.Metrics,
		topic:       cfg.Topic,
	}
}

// Send –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Kafka, —Å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º middleware –∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫.
func (p *Producer) Send(ctx context.Context, key string, value []byte) error {
	var err error
	for _, mw := range p.middlewares {
		key, value, err = mw(ctx, key, value)
		if err != nil {
			p.logger.WithContext(ctx).Error("‚ùå Middleware –æ—à–∏–±–∫–∞: %v", err)
			return err
		}
	}

	msg := kafka.Message{
		Key:   []byte(key),
		Value: value,
		Time:  time.Now(),
	}

	ctx, cancel := context.WithTimeout(ctx, 5*time.Second)
	defer cancel()

	err = p.writer.WriteMessages(ctx, msg)
	if err != nil {
		if p.metrics != nil {
			p.metrics.MessagesFailed.WithLabelValues(p.topic).Inc()
		}
		p.logger.WithContext(ctx).Error("‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Kafka: %v", err)
		return err
	}

	if p.metrics != nil {
		p.metrics.MessagesSent.WithLabelValues(p.topic).Inc()
	}
	p.logger.WithContext(ctx).Debug("üì§ –°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: key=%s", key)
	return nil
}

// SendEvent —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∫–∞–∫ JSON.
func (p *Producer) SendEvent(ctx context.Context, key string, event any) error {
	data, err := json.Marshal(event)
	if err != nil {
		p.logger.WithContext(ctx).Error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ: %v", err)
		return err
	}
	return p.Send(ctx, key, data)
}

// Close –∑–∞–∫—Ä—ã–≤–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Kafka.
func (p *Producer) Close() error {
	err := p.writer.Close()
	if err != nil {
		p.logger.Error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ Kafka producer: %v", err)
	} else {
		p.logger.Info("üîå Kafka producer –∑–∞–∫—Ä—ã—Ç")
	}
	return err
}
